# Behemot Framework

**Framework modular para crear asistentes IA multimodales**

La filosof√≠a es simple: **el framework proporciona el motor; t√∫ proporcionas la personalidad (configuraci√≥n) y las habilidades (herramientas).**

## üöÄ Inicio R√°pido

### Paso 1: Crear el Proyecto

```bash
# Crear directorio del proyecto
mkdir mi_asistente
cd mi_asistente

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### Paso 2: Instalar Behemot Framework

```bash
pip install git+https://github.com/hernandezbg/behemot_framework.git
```

### Paso 3: Generar Estructura del Proyecto

```bash
behemot-admin startia mi_asistente
```

Este comando crea autom√°ticamente:
- `config/mi_asistente.yaml` - Configuraci√≥n del asistente
- `tools/` - Directorio para herramientas personalizadas
- `main.py` - Punto de entrada principal
- `.env.example` - Plantilla de variables de entorno
- `README.md` - Documentaci√≥n del proyecto

### Paso 4: Configurar Variables de Entorno

```bash
cp .env.example .env
# Editar .env con tus API keys
```

### Paso 5: Ejecutar tu Asistente

```bash
python main.py
```

¬°Tu asistente estar√° corriendo en http://localhost:8000!

## üõ†Ô∏è Personalizaci√≥n Avanzada

### Configuraci√≥n del Asistente

Edita `config/mi_asistente.yaml` para personalizar tu asistente:

```yaml
# Configuraci√≥n del modelo
MODEL_PROVIDER: "openai"  # openai, gemini
MODEL_NAME: "gpt-4o-mini"

# Prompt del sistema - Define la personalidad de tu asistente
PROMPT_SISTEMA: |
  Eres un asistente especializado en [tu dominio].
  Siempre eres amable, preciso y √∫til.
  
# Configuraci√≥n de seguridad
SAFETY_LEVEL: "medium"  # low, medium, high

# RAG (Retrieval Augmented Generation) - Conocimiento personalizado
ENABLE_RAG: true
RAG_FOLDERS: ["./docs"]  # Carpetas locales, gcp://bucket/path, s3://bucket/key
RAG_EMBEDDING_PROVIDER: "openai"  # openai, google, huggingface
```

### Crear Herramientas Personalizadas

Las herramientas son las "habilidades" de tu asistente. Cr√©alas en el directorio `tools/`:

**`tools/mi_herramienta.py`:**
```python
from behemot_framework.tooling import tool, Param

@tool(
    "mi_herramienta",
    "Descripci√≥n de lo que hace la herramienta",
    [
        Param("parametro", "string", "Descripci√≥n del par√°metro", required=True)
    ]
)
async def mi_herramienta(parametro: str):
    # Tu l√≥gica aqu√≠
    return f"Resultado procesando: {parametro}"
```

Luego agr√©gala a `main.py`:
```python
app = create_behemot_app(
    # ... otras configuraciones
    use_tools=["mi_herramienta"],  # Agregar aqu√≠
)
```

### Habilitar RAG (Conocimiento Personalizado)

Agrega documentos a tu asistente para que responda bas√°ndose en tu contenido:

```yaml
# En config/mi_asistente.yaml
ENABLE_RAG: true
RAG_FOLDERS: ["./docs", "gcp://mi-bucket/documentos", "s3://bucket/archivos"]
```

**Formatos soportados**: PDF, TXT, Markdown, CSV, URLs
**El asistente leer√° autom√°ticamente** todo el contenido y podr√° responder preguntas sobre tus documentos.

### Habilitar Canales de Comunicaci√≥n

En `main.py`, activa los canales que necesites:

```python
app = create_behemot_app(
    enable_api=True,          # API REST
    enable_telegram=True,     # Bot de Telegram
    enable_whatsapp=True,     # WhatsApp Business
    enable_google_chat=True,  # Google Chat
    enable_voice=True,        # Procesamiento de voz
    enable_test_local=True,   # Interfaz de prueba local con Gradio
    config_path="config/mi_asistente.yaml",
)
```

### Interfaz de Prueba Local

Para probar tu asistente de forma visual antes de desplegarlo:

```python
# En main.py
app = create_behemot_app(
    enable_test_local=True,   # Activar interfaz visual
    config_path="config/mi_asistente.yaml",
)
```

Esto crear√° una interfaz web en http://localhost:7860 con:
- üí¨ **Chat interactivo** - Prueba conversaciones
- üé§ **Entrada de voz** - Si `enable_voice=True`
- üîß **Panel de herramientas** - Ve las herramientas disponibles
- ‚öôÔ∏è **Configuraci√≥n** - Revisa la configuraci√≥n actual

### Configurar Variables de Entorno

Edita tu archivo `.env`:

```bash
# OpenAI
GPT_API_KEY=sk-...

# Google Gemini (opcional)
GEMINI_API_KEY=AI...

# Redis para persistencia (opcional)
REDIS_PUBLIC_URL=redis://localhost:6379

# Telegram (opcional)
TELEGRAM_TOKEN=...
TELEGRAM_WEBHOOK_URL=https://tu-dominio.com/webhook

# WhatsApp Business (opcional)
WHATSAPP_TOKEN=...
WHATSAPP_VERIFY_TOKEN=...
WHATSAPP_WEBHOOK_URL=https://tu-dominio.com/whatsapp-webhook

# API REST - Para plataformas web personalizadas (opcional)
API_WEBHOOK_URL=https://tu-plataforma-web.com/api

# Google Chat (opcional)
GC_PROJECT_ID=...
GC_PRIVATE_KEY=...
GC_CLIENT_EMAIL=...
```

## üåü Caracter√≠sticas

- **ü§ñ M√∫ltiples Modelos IA**: OpenAI GPT y Google Gemini
- **üì± M√∫ltiples Canales**: API REST, Telegram, WhatsApp, Google Chat
- **üß† RAG Integrado**: Lee carpetas locales, GCP, S3, Google Drive autom√°ticamente
- **üîß Herramientas Extensibles**: Sistema de plugins simple
- **üé§ Procesamiento de Voz**: Transcripci√≥n autom√°tica de audio
- **üîí Filtros de Seguridad**: Contenido seguro por defecto
- **üíæ Persistencia de Contexto**: Conversaciones continuas con Redis
- **üìä Diagn√≥sticos**: Monitoreo autom√°tico de componentes

## üìö Documentaci√≥n Adicional

Para casos de uso avanzados, configuraciones especiales y ejemplos completos, consulta la documentaci√≥n en el repositorio.

## ü§ù Contribuir

¬°Las contribuciones son bienvenidas! Por favor:

1. Haz fork del repositorio
2. Crea una rama para tu feature
3. Haz commit de tus cambios
4. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.